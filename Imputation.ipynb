{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd             \n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "sns.set_context(rc={\"font.family\":'sans',\"font.size\":24,\"axes.titlesize\":24,\"axes.labelsize\":24})   \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523021, 36)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the variables that contain NANs (will need to be imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable that will need to be imputed ['CloudCover' 'Events' 'Max_Gust_SpeedKm_h' 'Max_VisibilityKm'\n",
      " 'Mean_VisibilityKm' 'Min_VisibilitykM']\n"
     ]
    }
   ],
   "source": [
    "#Isnull() checks for nans\n",
    "#any() returns true if there is any true in an array\n",
    "#values() then converts everything into a single array\n",
    "areasWithNansMask = train_data.isnull().any().values\n",
    "\n",
    "#This is how we access column titles\n",
    "areasWithNans = train_data.columns.values\n",
    "\n",
    "#using boolean indexing here\n",
    "areasWithNans = areasWithNans[areasWithNansMask]\n",
    "print(\"Variable that will need to be imputed\", areasWithNans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting the nan and non nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variables and the count of null and not null \n",
      "\n",
      "CloudCover Null values:\n",
      " Not Null    481840\n",
      "Null         41181\n",
      "Name: CloudCover, dtype: int64 \n",
      "\n",
      "Events Null values:\n",
      " Not Null    398923\n",
      "Null        124098\n",
      "Name: Events, dtype: int64 \n",
      "\n",
      "Max_Gust_SpeedKm_h Null values:\n",
      " Null        409947\n",
      "Not Null    113074\n",
      "Name: Max_Gust_SpeedKm_h, dtype: int64 \n",
      "\n",
      "Max_VisibilityKm Null values:\n",
      " Not Null    511683\n",
      "Null         11338\n",
      "Name: Max_VisibilityKm, dtype: int64 \n",
      "\n",
      "Mean_VisibilityKm Null values:\n",
      " Not Null    511683\n",
      "Null         11338\n",
      "Name: Mean_VisibilityKm, dtype: int64 \n",
      "\n",
      "Min_VisibilitykM Null values:\n",
      " Not Null    511683\n",
      "Null         11338\n",
      "Name: Min_VisibilitykM, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The variables and the count of null and not null \\n\")\n",
    "#After using the isnull function, replace all instances of false to string \"not null\" and true instances to \"Null\"\n",
    "#This makes it much more readable when using the value_counts function\n",
    "cloudCoverPrintList = train_data['CloudCover'].isnull().replace(False, \"Not Null\").replace(True, \"Null\").value_counts()\n",
    "print(\"CloudCover Null values:\\n\",cloudCoverPrintList, \"\\n\")\n",
    "\n",
    "eventsPrintList = train_data['Events'].isnull().replace(False, \"Not Null\").replace(True, \"Null\").value_counts()\n",
    "print(\"Events Null values:\\n\",eventsPrintList, \"\\n\")\n",
    "\n",
    "maxGustPrintList = train_data['Max_Gust_SpeedKm_h'].isnull().replace(False, \"Not Null\").replace(True, \"Null\").value_counts()\n",
    "print(\"Max_Gust_SpeedKm_h Null values:\\n\",maxGustPrintList, \"\\n\")\n",
    "\n",
    "maxVisPrintList=train_data['Max_VisibilityKm'].isnull().replace(False, \"Not Null\").replace(True, \"Null\").value_counts()\n",
    "print(\"Max_VisibilityKm Null values:\\n\",maxVisPrintList , \"\\n\")\n",
    "\n",
    "meanVisPrintList=train_data['Mean_VisibilityKm'].isnull().replace(False, \"Not Null\").replace(True, \"Null\").value_counts()\n",
    "print(\"Mean_VisibilityKm Null values:\\n\", meanVisPrintList, \"\\n\")\n",
    "\n",
    "minVisPrintList=train_data['Min_VisibilitykM'].isnull().replace(False, \"Not Null\").replace(True, \"Null\").value_counts()\n",
    "print(\"Min_VisibilitykM Null values:\\n\",minVisPrintList , \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation dropping rows\n",
    "\n",
    " \n",
    "We start with dropping the Max_Gust_SpeedKm_h column since it has too many missing values (as seen above in the variable count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the Max_Gust_SpeedKm_h column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Drop Max_Gust regardless because it has too many missing values\n",
    "droppingRows = droppingRows.drop(columns=\"Max_Gust_SpeedKm_h\")\n",
    "#print(\"Without Max gust speed now: \\n\",new.head())\n",
    "print(\"Without Max gust speed now: \\n\")\n",
    "print(droppingRows.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the Events\n",
    "Here we fix the events column, converting nans to some other value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the Events column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "droping rows with nans after fixing the events column\n",
      "The orginial data: \n",
      "\n",
      "(523021, 36)\n",
      "Without Events now: \n",
      "\n",
      "(523021, 35)\n"
     ]
    }
   ],
   "source": [
    "#droping rows with nans after fixing the events column\n",
    "print(\"droping rows with nans after fixing the events column\")\n",
    "Events = train_data['Events']\n",
    "Events = Events.fillna(\"Clear\")\n",
    "\n",
    "#Dropping columns\n",
    "#new = train_data.dropna(axis=1)\n",
    "\n",
    "#Dropping just events\n",
    "#print(\"The orginial data: \\n\", train_data.head())\n",
    "print(\"The orginial data: \\n\")\n",
    "print(train_data.shape)\n",
    "droppingRows = train_data.drop(columns=\"Events\")\n",
    "#print(\"Without Events now: \\n\",new.head())\n",
    "print(\"Without Events now: \\n\")\n",
    "print(droppingRows.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the events column back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droppingRows = droppingRows.assign(Events = Events.values)\n",
    "#print(new.describe())\n",
    "\n",
    "#Event has been added back in with \n",
    "#print(\"Events had been added back in: \\n\",new.head())\n",
    "print(\"Events had been added back in: \\n\")\n",
    "print(droppingRows.shape)\n",
    "droppingRows = droppingRows.dropna()\n",
    "print(\"After dropping nan values: \\n\")\n",
    "print(droppingRows.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "droping all columns with nans after fixing the events column\n",
      "The orginial data: \n",
      "\n",
      "(523021, 36)\n",
      "After dropping nan columns: \n",
      "\n",
      "(523021, 30)\n",
      "Events had been added back in: \n",
      "\n",
      "(523021, 31)\n"
     ]
    }
   ],
   "source": [
    "#droping all columns with nans after fixing the events column\n",
    "print(\"droping all columns with nans after fixing the events column\")\n",
    "Events = train_data['Events']\n",
    "Events = Events.fillna(\"Clear\")\n",
    "\n",
    "#Dropping columns\n",
    "#new = train_data.dropna(axis=1)\n",
    "\n",
    "#Dropping just events\n",
    "#print(\"The orginial data: \\n\", train_data.head())\n",
    "print(\"The orginial data: \\n\")\n",
    "print(train_data.shape)\n",
    "\n",
    "droppedColumns = train_data.dropna(axis=1)\n",
    "print(\"After dropping nan columns: \\n\")\n",
    "print(droppedColumns.shape)\n",
    "\n",
    "droppedColumns = droppedColumns.assign(Events = Events.values)\n",
    "#print(new.describe())\n",
    "#print(\"Events had been added back in: \\n\",new.head())\n",
    "print(\"Events had been added back in: \\n\")\n",
    "print(droppedColumns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
